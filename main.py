from fastapi import FastAPI, UploadFile, File, Form, HTTPException
from fastapi.templating import Jinja2Templates
from fastapi.responses import HTMLResponse, FileResponse
from starlette.requests import Request
from pydantic import BaseModel
from typing import List, Tuple, Optional, Union
import speech_recognition as sr
import google.generativeai as genai
from fastapi.staticfiles import StaticFiles
import tempfile
import os
import base64
import json
import subprocess
from pydub import AudioSegment
import uuid
from pathlib import Path
import asyncio
import shutil
from emotion_reg import recognize_text_and_emotion_from_audio, analyze_emotion_from_text

# C·∫•u h√¨nh Gemini
genai.configure(api_key='AIzaSyDuuYd4K81PgG9C00Onw-XgwgvJ93DYnqI')
model = genai.GenerativeModel(model_name='tunedModels/generate-emotion-response-1000')

os.environ["PYTHONIOENCODING"] = "utf-8"
app = FastAPI()
app.mount("/static", StaticFiles(directory="static"), name="static")

TEMP_AUDIO_DIR = Path("temp_audio")
TEMP_AUDIO_DIR.mkdir(exist_ok=True)

# ƒê·∫£m b·∫£o th∆∞ m·ª•c assets/infore t·ªìn t·∫°i
BASE_DIR = Path(__file__).resolve().parent  # Ho·∫∑c ƒë∆∞·ªùng d·∫´n g·ªëc d·ª± √°n c·ªßa b·∫°n

# Thi·∫øt l·∫≠p ƒë∆∞·ªùng d·∫´n tuy·ªát ƒë·ªëi ƒë·∫øn th∆∞ m·ª•c assets
ASSETS_DIR = BASE_DIR / "tts" / "vietTTS" / "assets" / "infore"
ASSETS_DIR.mkdir(exist_ok=True, parents=True)

# ƒê∆∞·ªùng d·∫´n tuy·ªát ƒë·ªëi ƒë·∫øn file lexicon.txt
LEXICON_FILE = ASSETS_DIR / "lexicon.txt"

# ƒê∆∞·ªùng d·∫´n ƒë·∫øn file lexicon.txt
LEXICON_FILE = ASSETS_DIR / "lexicon.txt"

class TTSRequest(BaseModel):
    text: str 

# ƒê·ªãnh nghƒ©a m√¥ h√¨nh d·ªØ li·ªáu
class TextMessageData(BaseModel):
    message: str
    chat_history: List[Tuple[str, str]]

class AudioData(BaseModel):
    base64_audio: str
    chat_history: List[Tuple[str, str]]

class MessageRequest(BaseModel):
    message_type: str  # "text" ho·∫∑c "audio"
    content: Union[str, dict]  # N·ªôi dung tin nh·∫Øn (text ho·∫∑c audio_data)
    chat_history: List[Union[Tuple[str, str], Tuple[str, str, str]]]

# T·∫°o ƒë·ªëi t∆∞·ª£ng templates ƒë·ªÉ render file HTML
templates = Jinja2Templates(directory="templates")

@app.post("/api/tts")
async def text_to_speech(request: TTSRequest):
    """
    Endpoint t·∫°o file √¢m thanh t·ª´ vƒÉn b·∫£n ti·∫øng Vi·ªát s·ª≠ d·ª•ng VietTTS CLI
    """
    try:
        audio_id = str(uuid.uuid4())
        output_path = ASSETS_DIR / f"clip_{audio_id}.wav"
        
        # ƒê∆∞·ªùng d·∫´n tuy·ªát ƒë·ªëi ƒë·∫øn th∆∞ m·ª•c g·ªëc c·ªßa VietTTS
        vietTTS_root = Path("tts/vietTTS").absolute()
        
        # Chu·∫©n b·ªã l·ªánh ch·∫°y VietTTS
        cmd = [
            "python", 
            "-m", 
            "vietTTS.synthesizer", 
            "--text", request.text,
            "--output", str(output_path),
            "--lexicon-file", str(LEXICON_FILE),
            "--silence-duration", "0.2"
        ]
        print(cmd)
        
        # Thi·∫øt l·∫≠p m√¥i tr∆∞·ªùng v·ªõi UTF-8
        env = os.environ.copy()
        env["PYTHONIOENCODING"] = "utf-8"
        
        # Th·ª±c thi l·ªánh v·ªõi th∆∞ m·ª•c l√†m vi·ªác ƒë∆∞·ª£c ch·ªâ ƒë·ªãnh
        process = subprocess.Popen(
            cmd, 
            stdout=subprocess.PIPE, 
            stderr=subprocess.PIPE,
            cwd=str(vietTTS_root),  # Ch·ªâ ƒë·ªãnh th∆∞ m·ª•c l√†m vi·ªác l√† th∆∞ m·ª•c g·ªëc c·ªßa VietTTS
            env=env,  # S·ª≠ d·ª•ng bi·∫øn m√¥i tr∆∞·ªùng ƒë√£ thi·∫øt l·∫≠p
            text=True,  # X·ª≠ l√Ω I/O d∆∞·ªõi d·∫°ng text thay v√¨ bytes
            encoding='utf-8'  # ƒê·∫£m b·∫£o x·ª≠ l√Ω ƒë√∫ng k√Ω t·ª± ti·∫øng Vi·ªát
        )
        stdout, stderr = process.communicate()
        
        if process.returncode != 0:
            print(f"L·ªói khi t·∫°o √¢m thanh: {stderr.decode('utf-8')}")
            raise HTTPException(status_code=500, detail=f"VietTTS error: {stderr.decode('utf-8')}")
        
        # Copy file t·ª´ assets/infore v√†o th∆∞ m·ª•c t·∫°m ƒë·ªÉ ph·ª•c v·ª• web
        temp_file_path = TEMP_AUDIO_DIR / f"{audio_id}.wav"
        shutil.copy2(output_path, temp_file_path)
        
        # X√≥a file g·ªëc trong assets/infore ƒë·ªÉ tr√°nh t√≠ch t·ª• file
        if output_path.exists():
            output_path.unlink()
        
        # ƒêƒÉng k√Ω file n√†y ƒë·ªÉ x√≥a sau khi ph√°t
        return {"audio_url": f"/api/audio/{audio_id}.wav", "audio_id": audio_id}
            
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/audio/{filename}")
async def get_audio(filename: str):
    """
    Endpoint ƒë·ªÉ l·∫•y file √¢m thanh ƒë√£ t·∫°o
    """
    file_path = TEMP_AUDIO_DIR / filename
    
    if not file_path.exists():
        raise HTTPException(status_code=404, detail="Kh√¥ng t√¨m th·∫•y file √¢m thanh")
    
    return FileResponse(
        path=str(file_path),
        media_type="audio/wav",
        headers={"Content-Disposition": f"attachment; filename={filename}"}
    )

@app.delete("/api/audio/{audio_id}")
async def delete_audio(audio_id: str):
    """
    Endpoint ƒë·ªÉ x√≥a file √¢m thanh sau khi ƒë√£ ph√°t xong
    """
    file_path = TEMP_AUDIO_DIR / f"{audio_id}.wav"
    
    if file_path.exists():
        file_path.unlink()
        return {"success": True, "message": "File ƒë√£ ƒë∆∞·ª£c x√≥a"}
    
    return {"success": False, "message": "File kh√¥ng t·ªìn t·∫°i"}

# ƒê·ªãnh k·ª≥ x√≥a c√°c file √¢m thanh t·∫°m
@app.on_event("startup")
async def startup_event():
    asyncio.create_task(cleanup_temp_files())

async def cleanup_temp_files():
    """
    X√≥a c√°c file √¢m thanh t·∫°m c≈©
    """
    import time
    while True:
        try:
            current_time = time.time()
            for file_path in TEMP_AUDIO_DIR.glob("*"):
                # X√≥a file c≈© h∆°n 1 gi·ªù
                if current_time - file_path.stat().st_mtime > 3600:
                    file_path.unlink()
        except Exception as e:
            print(f"L·ªói khi d·ªçn d·∫πp file t·∫°m: {e}")
        
        # Ki·ªÉm tra m·ªói 30 ph√∫t
        await asyncio.sleep(1800)

# API nh·∫≠n d·ªØ li·ªáu tin nh·∫Øn (text ho·∫∑c audio) v√† tr·∫£ v·ªÅ ph·∫£n h·ªìi
@app.post("/process_message")
async def process_message(data: MessageRequest):
    chat_history = data.chat_history
    message_type = data.message_type
    print(chat_history)
    try:
        if message_type == "text":
            # X·ª≠ l√Ω tin nh·∫Øn vƒÉn b·∫£n
            text_message = data.content
            print(text_message)
            emotion = analyze_emotion_from_text(text_message)
            print(emotion)
            if not text_message:
                return {"chat_history": chat_history}
            
            # T·∫°o ph·∫£n h·ªìi t·ª´ Gemini
            response = model.generate_content(f"[{emotion}] {text_message}")
            generated_text = response.candidates[0].content.parts[0].text
            
            # Th√™m tin nh·∫Øn v√†o l·ªãch s·ª≠ tr√≤ chuy·ªán
            chat_history.append((f"üßë B·∫°n: {text_message}", f"{generated_text}"))
            
        elif message_type == "audio":
            # X·ª≠ l√Ω tin nh·∫Øn audio
            print('This is audio')
            base64_audio = data.content.get("base64_audio", "")
            if not base64_audio:
                return {"chat_history": chat_history}
            
            # Chuy·ªÉn ƒë·ªïi base64 th√†nh d·ªØ li·ªáu nh·ªã ph√¢n
            audio_data = base64.b64decode(base64_audio)
            
            # L∆∞u v√†o file t·∫°m
            with tempfile.NamedTemporaryFile(delete=False, suffix=".webm") as temp_file:
                temp_file.write(audio_data)
                temp_input_path = temp_file.name
            
            sound = AudioSegment.from_file(temp_input_path)
    
            # T·∫°o file WAV m·ªõi ƒë·ªÉ s·ª≠ d·ª•ng v·ªõi SpeechRecognition
            temp_wav_file = tempfile.NamedTemporaryFile(delete=False, suffix=".wav")
            temp_wav_path = temp_wav_file.name
            temp_wav_file.close()
            
            # Export sang ƒë·ªãnh d·∫°ng WAV PCM
            sound.export(temp_wav_path, format="wav")

            try:
                # Nh·∫≠n di·ªán gi·ªçng n√≥i
                recognizer = sr.Recognizer()
                with sr.AudioFile(temp_wav_path) as source:
                    audio = recognizer.record(source)
                    text = recognizer.recognize_google(audio, language="vi-VN")  # S·ª≠ d·ª•ng nh·∫≠n di·ªán ti·∫øng Vi·ªát
                # print("before reg")
                # text, emotion = recognize_text_and_emotion_from_audio(temp_wav_path)
                emotion = analyze_emotion_from_text(text)
                print(f"Emotion: {emotion}")
                print(f"Nh·∫≠n di·ªán gi·ªçng n√≥i: {text}")
                
                # T·∫°o ph·∫£n h·ªìi t·ª´ Gemini
                response = model.generate_content(f"[{emotion}] {text}")
                generated_text = response.candidates[0].content.parts[0].text
                
                # L∆∞u audio g·ªëc v√†o th∆∞ m·ª•c static (t√πy ch·ªçn)
                audio_filename = f"audio_{len(chat_history)}.wav"
                audio_path = os.path.join("static", "uploads", audio_filename)
                os.makedirs(os.path.dirname(audio_path), exist_ok=True)
                with open(audio_path, "wb") as audio_file:
                    audio_file.write(audio_data)
                
                # Th√™m tin nh·∫Øn v√†o l·ªãch s·ª≠ tr√≤ chuy·ªán, k√®m theo ƒë∆∞·ªùng d·∫´n ƒë·∫øn file audio
                chat_history.append((
                    f"üßë B·∫°n (Mic): {text}", 
                    f"{generated_text}",
                    f"/static/uploads/{audio_filename}"  # Audio URL ƒë·ªÉ ph√°t l·∫°i
                ))
                
            except sr.UnknownValueError:
                chat_history.append((
                    "üßë B·∫°n (Mic): (Kh√¥ng nh·∫≠n di·ªán ƒë∆∞·ª£c)", 
                    "Xin l·ªói, t√¥i kh√¥ng nghe r√µ. B·∫°n c√≥ th·ªÉ th·ª≠ l·∫°i kh√¥ng?"
                ))
            finally:
                # X√≥a file t·∫°m
                if os.path.exists(temp_wav_path):
                    os.remove(temp_wav_path)
        else:
            return {"error": "Kh√¥ng h·ªó tr·ª£ lo·∫°i tin nh·∫Øn n√†y"}
            
    except Exception as e:
        chat_history.append((f"üßë B·∫°n: (L·ªói x·ª≠ l√Ω)", f"R·∫•t ti·∫øc, kh√¥ng c√≥ k·∫øt qu·∫£ ph√π h·ª£p ƒë∆∞·ª£c t√¨m th·∫•y cho y√™u c·∫ßu c·ªßa b·∫°n. Vui l√≤ng th·ª≠ l·∫°i v·ªõi m·ªôt c√¢u h·ªèi ho·∫∑c y√™u c·∫ßu kh√°c."))
    
    # Tr·∫£ v·ªÅ l·ªãch s·ª≠ tr√≤ chuy·ªán m·ªõi nh·∫•t
    return {"chat_history": chat_history}

# API x·ª≠ l√Ω tin nh·∫Øn text (gi·ªØ l·∫°i cho t∆∞∆°ng th√≠ch)
@app.post("/process_text")
async def process_text(data: TextMessageData):
    chat_history = data.chat_history
    text_message = data.message
    
    if not text_message:
        return {"chat_history": chat_history}
    
    try:
        # T·∫°o ph·∫£n h·ªìi t·ª´ Gemini
        response = model.generate_content(text_message)
        generated_text = response.candidates[0].content.parts[0].text
        
        # Th√™m tin nh·∫Øn v√†o l·ªãch s·ª≠ tr√≤ chuy·ªán
        chat_history.append((f"üßë B·∫°n: {text_message}", f"{generated_text}"))
        
    except Exception as e:
        chat_history.append((f"üßë B·∫°n: {text_message}", f"‚ùå L·ªói: {str(e)}"))
    
    # Tr·∫£ v·ªÅ l·ªãch s·ª≠ tr√≤ chuy·ªán m·ªõi nh·∫•t
    return {"chat_history": chat_history}

# API x·ª≠ l√Ω tin nh·∫Øn audio (gi·ªØ l·∫°i cho t∆∞∆°ng th√≠ch)
@app.post("/process_audio")
async def process_audio(data: AudioData):
    chat_history = data.chat_history
    base64_audio = data.base64_audio
    
    if not base64_audio:
        return {"chat_history": chat_history}
    
    try:
        # Chuy·ªÉn ƒë·ªïi base64 th√†nh d·ªØ li·ªáu nh·ªã ph√¢n
        audio_data = base64.b64decode(base64_audio)
        
        # L∆∞u v√†o file t·∫°m
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_file:
            tmp_file.write(audio_data)
            tmp_filename = tmp_file.name
        
        # L∆∞u b·∫£n sao file audio ƒë·ªÉ sau n√†y c√≥ th·ªÉ ph√°t l·∫°i (t√πy ch·ªçn)
        print("Before save")
        audio_filename = f"audio_{len(chat_history)}.wav"
        audio_path = os.path.join("static", "uploads", audio_filename)
        os.makedirs(os.path.dirname(audio_path), exist_ok=True)
        with open(audio_path, "wb") as audio_file:
            audio_file.write(audio_data)
        
        
        # Nh·∫≠n di·ªán gi·ªçng n√≥i
        recognizer = sr.Recognizer()
        with sr.AudioFile(tmp_filename) as source:
            audio = recognizer.record(source)
            text = recognizer.recognize_google(audio, language="vi-VN")  # S·ª≠ d·ª•ng nh·∫≠n di·ªán ti·∫øng Vi·ªát
        
        print(f"Nh·∫≠n di·ªán gi·ªçng n√≥i: {text}")
        
        # T·∫°o ph·∫£n h·ªìi t·ª´ Gemini
        response = model.generate_content(text)
        generated_text = response.candidates[0].content.parts[0].text
        
        # Th√™m tin nh·∫Øn v√†o l·ªãch s·ª≠ tr√≤ chuy·ªán, k√®m theo ƒë∆∞·ªùng d·∫´n file audio
        chat_history.append((
            f"üßë B·∫°n (Mic): {text}", 
            f"{generated_text}",
            f"/static/uploads/{audio_filename}"  # Audio URL
        ))
        
    except sr.UnknownValueError:
        chat_history.append((
            "üßë B·∫°n (Mic): (Kh√¥ng nh·∫≠n di·ªán ƒë∆∞·ª£c)", 
            "Xin l·ªói, t√¥i kh√¥ng nghe r√µ. B·∫°n c√≥ th·ªÉ th·ª≠ l·∫°i kh√¥ng?"
        ))
    except Exception as e:
        chat_history.append((
            "üßë B·∫°n (Mic): (L·ªói x·ª≠ l√Ω audio)", 
            f"R·∫•t ti·∫øc, kh√¥ng c√≥ k·∫øt qu·∫£ ph√π h·ª£p ƒë∆∞·ª£c t√¨m th·∫•y cho y√™u c·∫ßu c·ªßa b·∫°n. Vui l√≤ng th·ª≠ l·∫°i v·ªõi m·ªôt c√¢u h·ªèi ho·∫∑c y√™u c·∫ßu kh√°c."
        ))
    finally:
        # X√≥a file t·∫°m
        if 'tmp_filename' in locals() and os.path.exists(tmp_filename):
            os.remove(tmp_filename)
    
    # Tr·∫£ v·ªÅ l·ªãch s·ª≠ tr√≤ chuy·ªán m·ªõi nh·∫•t v√† URL c·ªßa file audio
    return {
        "chat_history": chat_history,
        "audio_url": f"/static/uploads/{audio_filename}" if 'audio_filename' in locals() else None
    }

# Route ƒë·ªÉ render index.html
@app.get("/", response_class=HTMLResponse)
async def get_index(request: Request):
    return templates.TemplateResponse("index.html", {"request": request})

# API ƒë·ªÉ l·∫•y danh s√°ch c√°c file audio ƒë√£ l∆∞u
@app.get("/get_audio_files")
async def get_audio_files():
    uploads_dir = os.path.join("static", "uploads")
    if not os.path.exists(uploads_dir):
        return {"audio_files": []}
    
    files = [f for f in os.listdir(uploads_dir) if f.endswith('.wav')]
    return {"audio_files": files}

# API ƒë·ªÉ l·∫•y file audio c·ª• th·ªÉ
@app.get("/get_audio/{filename}")
async def get_audio(filename: str):
    audio_path = os.path.join("static", "uploads", filename)
    if not os.path.exists(audio_path):
        return {"error": "File kh√¥ng t·ªìn t·∫°i"}
    
    with open(audio_path, "rb") as audio_file:
        audio_data = audio_file.read()
    
    return {"audio_data": base64.b64encode(audio_data).decode('utf-8')}